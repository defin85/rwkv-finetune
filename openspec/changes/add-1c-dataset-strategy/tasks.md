## 1. Спецификация и структура данных
- [ ] 1.1 Утвердить schema версии датасета и `manifest` (поля provenance, лицензии, quality-гейтов, split).
- [ ] 1.2 Зафиксировать структуру каталогов данных (`raw/interim/curated`) и правила именования версий.

## 2. Подготовка данных и нормализация
- [ ] 2.1 Реализовать ingest-конвейер для двух контуров (`core`, `extended`) с фиксацией источника в `manifest`.
- [ ] 2.2 Реализовать нормализацию в единый формат `text` (`User/Assistant`) с обязательной проверкой: промпт на русском языке.
- [ ] 2.3 Реализовать классификацию образцов по четырём категориям задач и отчёт по фактическому балансу категорий.

## 3. Качество и безопасность датасета
- [ ] 3.1 Реализовать exact/near dedup и запись результатов группировки дубликатов в `manifest`.
- [ ] 3.2 Реализовать quality gates: BSL parse/diagnostics, фильтрация секретов/PII, отбраковка некорректных образцов.
- [ ] 3.3 Реализовать контроль leakage между train/eval с блокировкой релиза при нарушении порога.

## 4. Разделение и выпуск версии
- [ ] 4.1 Реализовать split по репозиториям и времени с отдельными eval-наборами для генерации и рефакторинга.
- [ ] 4.2 Реализовать экспорт `train.jsonl` для `scripts/prepare_binidx.sh` и выпуск `manifest` как артефакта версии.
- [ ] 4.3 Добавить pre-release проверку baseline-баланса категорий (35/35/15/15, допуск 5 п.п.) с блокировкой релиза при нарушении.

## 5. Валидация результата и документация
- [ ] 5.1 Провести smoke-проход: `prepare_binidx.sh` на релизном `train.jsonl` и проверить валидность `data_prefix`.
- [ ] 5.2 Обновить документацию по lifecycle датасетов, quality gates и процедуре выпуска.
- [ ] 5.3 Подготовить отчёт по v0: состав датасета, метрики качества, результаты eval и backlog hard-cases.

## 6. Зависимости и порядок выполнения
- [ ] 6.1 Зависимость: блок 1 MUST быть завершён до блоков 2-4.
- [ ] 6.2 Зависимость: блок 3 MUST быть завершён до выпуска из блока 4.
- [ ] 6.3 Параллелизация: задачи 5.2 и 5.3 можно выполнять параллельно после 5.1.
